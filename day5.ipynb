{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1XUPistuK5JiFyTUXdKWMjUAaU9ODo7gr",
      "authorship_tag": "ABX9TyM+vz2UJU0nIF+3H0cdaPq5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muzamiliqbalganaie/machine-learning-model-/blob/main/day5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDcTo7pUBxkn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "ARIMA and Seasonal ARIMA\n",
        "Autoregressive Integrated Moving Averages\n",
        "The general process for ARIMA models is the following:\n",
        "\n",
        "Visualize the Time Series Data\n",
        "Make the time series data stationary\n",
        "Plot the Correlation and AutoCorrelation Charts\n",
        "Construct the ARIMA Model or Seasonal ARIMA based on the data\n",
        "Use the model to make predictions#Time Series Day 4 Part 2"
      ],
      "metadata": {
        "id": "swkCxJgeCDW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/perrin-freres-monthly-champagne-.csv')"
      ],
      "metadata": {
        "id": "VwsNVwQRCZwR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "656ad24f-8ade-47b0-b8e8-53567dcb2082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/perrin-freres-monthly-champagne-.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4158646253>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/perrin-freres-monthly-champagne-.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/perrin-freres-monthly-champagne-.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Gjjj1rRzCzqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "juI_YiJJC3r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning up the data\n",
        "df.columns=[\"Month\",\"Sales\"]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "C2RsS0pDC9-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Drop last 2 rows\n",
        "df.drop(105,axis=0,inplace=True)\n",
        "df.tail()\n"
      ],
      "metadata": {
        "id": "x-cyUe2rDHN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N5Xqq50-GIv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Drop last 2 rows\n",
        "df.drop(106,axis=0,inplace=True)\n",
        "df.tail()\n"
      ],
      "metadata": {
        "id": "iqBc84leGJeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Month into Datetime\n",
        "\n",
        "df['Month']=pd.to_datetime(df['Month'])"
      ],
      "metadata": {
        "id": "KNy3JQ8_EAcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "eTNQ3cjwER12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "vs6j4tB_ZWti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "fB71ttedZBg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot()"
      ],
      "metadata": {
        "id": "UOshUHX3odh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to test the stationary\n",
        "from statsmodels.tsa.stattools import adfuller"
      ],
      "metadata": {
        "id": "gjQtR74zo9LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_result=adfuller(df['Sales'])"
      ],
      "metadata": {
        "id": "yfVRJ_U1pgUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adfuller_test(Sales):\n",
        "  result=adfuller(Sales)\n",
        "  labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
        "  for value,label in zip(result,labels):\n",
        "        print(label+' : '+str(value) )\n",
        "  if result[1] <= 0.05:\n",
        "        print(\"strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data has no unit root and is stationary\")\n",
        "  else:\n",
        "        print(\"weak evidence against null hypothesis, time series has a unit root, indicating it is non-stationary \")\n"
      ],
      "metadata": {
        "id": "it6JjxTupr02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The above Python code defines a function adfuller_test(sales) that performs the Augmented Dickey-Fuller test on a time series data represented by the input sales.\n",
        "\n",
        "result = adfuller(sales): The function first calculates the Augmented Dickey-Fuller test statistics by calling the adfuller() function from a suitable library (not shown in the code snippet). The adfuller() function returns a tuple containing various test statistics and critical values required for the test.\n",
        "\n",
        "labels list: This list holds the labels for the test statistics, namely 'ADF Test Statistic', 'p-value', '#Lags Used', and 'Number of Observations Used'.\n",
        "\n",
        "for value, label in zip(result, labels): The code uses a zip() function to iterate through the elements of the result tuple and the labels list simultaneously. In each iteration, it pairs the test statistic value with its corresponding label.\n",
        "\n",
        "print(label + ' : ' + str(value)): The loop prints each test statistic along with its label to display the results of the Augmented Dickey-Fuller test.\n",
        "\n",
        "The code then checks whether the p-value (result[1]) is less than or equal to 0.05. If the p-value is less than or equal to 0.05, it implies strong evidence against the null hypothesis (Ho) and concludes that the data has no unit root, indicating stationarity. The message \"strong evidence against the null hypothesis (Ho), reject the null hypothesis. Data has no unit root and is stationary\" is printed in this case.\n",
        "\n",
        "If the p-value is greater than 0.05, it suggests weak evidence against the null hypothesis, indicating that the time series may have a unit root and is non-stationary. The message \"weak evidence against the null hypothesis, time series has a unit root, indicating it is non-stationary\" is printed in this scenario.\n",
        "\n",
        "The Augmented Dickey-Fuller test is commonly used to check the stationarity of time series data. If the data is stationary, it means the mean and variance of the series do not change over time, which is a fundamental assumption for many time series analyses. On the other hand, non-stationary data tends to have trends or other time-dependent patterns, making it unsuitable for certain time series modeling techniques.\n",
        "\n"
      ],
      "metadata": {
        "id": "AjiRa1AMrpha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adfuller_test(df['Sales'])"
      ],
      "metadata": {
        "id": "uhMHD03Tr-mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Differencing**\n"
      ],
      "metadata": {
        "id": "5ccwAa3ishGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sales First Difference'] = df['Sales'] - df['Sales'].shift(1)"
      ],
      "metadata": {
        "id": "Ln51m2txsSdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code you provided calculates the first difference of the 'Sales' column in the DataFrame df and creates a new column called 'Sales First Difference' to store the result.\n",
        "\n",
        "Let's break down the code step by step:\n",
        "\n",
        "1. df['Sales']: This selects the 'Sales' column from the DataFrame df.\n",
        "\n",
        "2. df['Sales'].shift(1): The .shift() function is used to shift the values of the 'Sales' column one step backward. This effectively creates a new series where each element is the previous element of the 'Sales' column.\n",
        "\n",
        "3. df['Sales'] - df['Sales'].shift(1): This performs the element-wise subtraction between the 'Sales' column and its shifted version. The result is a new pandas Series representing the first difference of the 'Sales' column. The first element of this new Series will be NaN since there is no previous element to subtract from.\n",
        "\n",
        "4. df['Sales First Difference'] = ...: This assigns the calculated first difference series to a new column named 'Sales First Difference' in the DataFrame df.\n",
        "\n",
        "The first difference is a common transformation used in time series analysis. It represents the change between consecutive data points and is often used to stabilize the variance or remove trends in the data. The resulting 'Sales First Difference' column will contain the differences between consecutive 'Sales' values, making it a new time series that can be further analyzed or used in modeling.\n"
      ],
      "metadata": {
        "id": "OMeAglJJtFxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sales'].shift(1)"
      ],
      "metadata": {
        "id": "T31Oc3d3tJs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Seasonal First Difference'] = df['Sales'] - df['Sales'].shift(12)"
      ],
      "metadata": {
        "id": "IRs3OS90JAoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(14)"
      ],
      "metadata": {
        "id": "-66iyrfHJlZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Again test dickey fuller test\n",
        "adfuller_test(df['Seasonal First Difference'].dropna())"
      ],
      "metadata": {
        "id": "7SteC1MOJp3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Seasonal First Difference'].plot()"
      ],
      "metadata": {
        "id": "i-N6PRk9KPd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ARIMA &->\n",
        "# SARIMA -> USED FOR FORCASTING DATAS\n",
        "\n",
        "# (AR)->[Auto regressive(p)] (I)->[Integration/Defference]  (MA)->[Moving Average]\n",
        "# SAR I MA  -> Seasonal ARIMA"
      ],
      "metadata": {
        "id": "O9_6R2U7ME48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wQRPt98UtCj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from pandas.plotting import autocorrelation_plot\n",
        "autocorrelation_plot(df['Sales'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FO5yorqWLDpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BJC14wLNpMPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n"
      ],
      "metadata": {
        "id": "bLRjyFlGLD3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(12,8))\n",
        "ax1 = fig.add_subplot(211)\n",
        "fig = sm.graphics.tsa.plot_acf(df['Seasonal First Difference'].iloc[13:],lags=40,ax=ax1)\n",
        "ax2 = fig.add_subplot(212)\n",
        "fig = sm.graphics.tsa.plot_pacf(df['Seasonal First Difference'].iloc[13:],lags=40,ax=ax2)"
      ],
      "metadata": {
        "id": "6-YdeouwPvQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "The provided Python code uses the matplotlib and statsmodels libraries to create a figure with two subplots, each showing the Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots of a seasonal first difference time series data.\n",
        "\n",
        "Let's break down the code step by step:\n",
        "\n",
        "fig = plt.figure(figsize=(12, 8)): This creates a new matplotlib figure with a size of 12x8 inches.\n",
        "\n",
        "ax1 = fig.add_subplot(211): This adds the first subplot (ACF plot) to the figure. The 211 in the add_subplot() function indicates that there will be 2 rows, 1 column, and this subplot is the first one (top subplot).\n",
        "\n",
        "fig = sm.graphics.tsa.plot_acf(df['Seasonal First Difference'].iloc[13:],lags=40,ax=ax1): This generates the ACF plot using the plot_acf() function from statsmodels.tsa.graphics. The data used for the ACF plot is df['Seasonal First Difference'].iloc[13:], which represents the seasonal first difference time series data. The lags parameter specifies the number of lags to include in the ACF plot, and ax=ax1 ensures that the plot is displayed in the first subplot.\n",
        "\n",
        "ax2 = fig.add_subplot(212): This adds the second subplot (PACF plot) to the figure. The 212 in the add_subplot() function indicates that there will be 2 rows, 1 column, and this subplot is the second one (bottom subplot).\n",
        "\n",
        "fig = sm.graphics.tsa.plot_pacf(df['Seasonal First Difference'].iloc[13:],lags=40,ax=ax2): This generates the PACF plot using the plot_pacf() function from statsmodels.tsa.graphics. The data used for the PACF plot is the same as in the ACF plot (df['Seasonal First Difference'].iloc[13:]). The lags parameter specifies the number of lags to include in the PACF plot, and ax=ax2 ensures that the plot is displayed in the second subplot.\n",
        "\n",
        "The resulting figure will contain two subplots, where the top subplot shows the ACF plot and the bottom subplot shows the PACF plot of the seasonal first difference time series data. These plots are useful for identifying the potential order of the seasonal autoregressive and moving average components in a seasonal time series model, such as SARIMA (Seasonal Autoregressive Integrated Moving Average)."
      ],
      "metadata": {
        "id": "vA5ji87JSAvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For non-seasonal data\n",
        "#p=1, d=1, q=0 or 1\n",
        "from statsmodels.tsa.arima.model import ARIMA"
      ],
      "metadata": {
        "id": "fupWciOcSUFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=ARIMA(df['Sales'],order=(1,1,1))\n",
        "model_fit=model.fit()\n"
      ],
      "metadata": {
        "id": "9Z9AY6XASY4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fit.summary()"
      ],
      "metadata": {
        "id": "qbIba79dTvcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['forecast']=model_fit.predict(start=90,end=103,dynamic=True)\n",
        "df[['Sales','forecast']].plot(figsize=(12,8))"
      ],
      "metadata": {
        "id": "tHzm7iDRULgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "b6MgPLt4UcWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=sm.tsa.statespace.SARIMAX(df['Sales'],order=(1, 1, 1),seasonal_order=(1,1,1,12))\n",
        "results=model.fit()"
      ],
      "metadata": {
        "id": "UQlAikAkUeuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['forecast']=results.predict(start=90,end=103,dynamic=True)\n",
        "df[['Sales','forecast']].plot(figsize=(12,8))"
      ],
      "metadata": {
        "id": "HbpDUzugUjQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.tseries.offsets import DateOffset\n",
        "\n",
        "future_dates=[df.index[-1] + np.datetime64(Months=)for x in range(0,24)]"
      ],
      "metadata": {
        "id": "_dE1VftEVBhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "future_datest_df.tail()"
      ],
      "metadata": {
        "id": "hbE3Ty8JVe21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "future_datest_df=pd.DataFrame(index=future_dates[1:],columns=df.columns)"
      ],
      "metadata": {
        "id": "nfLhL59kVdPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.tseries.offsets import DateOffset\n",
        "future_dates=[df.index[-1]+ DateOffset(months=x)for x in range(0,24)]"
      ],
      "metadata": {
        "id": "LXtK248rpNVd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}